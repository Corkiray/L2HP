# Prices vary for respective API providers. Default prices may not reflect current prices.

# [Structure template]
# {PROVIDER}:
#   {MODEL_NAME}:
#     family: {FAMILY_NAME}
#     engine: {MODEL_API_NAME}
#     max_completion_tokens: 
#     temperature:
#     top_p:
#     context_length:
#     stop:

openai:
  o1:
    family: o1
    engine: o1
    model_params:
      context_length: 8192 # max: 200k
      max_completion_tokens: 8192 # max: 100k
      temperature: 1.0
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0
      stop:
      reasoning_effort: medium
    cost_usd_mtok:
      input: 15.00
      output: 60.00
  o1-mini:
    family: o1
    engine: o1-mini
    model_params:
      context_length: 8192 # max: 128k
      max_completion_tokens: 8192 # max: 65536
      temperature: 1.0
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0
      stop:
    cost_usd_mtok:
      input: 1.10
      output: 4.40
  o3:
    family: o3
    engine: o3
    model_params:
      context_length: 8192 # max: 200k
      max_completion_tokens: 8192 # max: 100k
      temperature: 1.0
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0
      stop:
      reasoning_effort: medium
    cost_usd_mtok:
      input: 10.00
      output: 40.00
  o3-mini:
    family: o3
    engine: o3-mini
    model_params:
      context_length: 8192 # max: 200k
      max_completion_tokens: 8192 # max: 100k
      temperature: 1.0
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0
      stop:
      reasoning_effort: medium
    cost_usd_mtok:
      input: 1.10
      output: 4.40
  o4-mini:
    family: o4
    engine: o4-mini
    model_params:
      context_length: 8192 # max: 200k
      max_completion_tokens: 8192 # max: 100k
      temperature: 1.0
      top_p: 1
      frequency_penalty: 0.0
      presence_penalty: 0.0
      stop:
      reasoning_effort: medium
    cost_usd_mtok:
      input: 1.10
      output: 4.40
  gpt-4.1:
    family: gpt-4.1
    engine: gpt-4.1
    model_params:
      context_length: 8192 # max: 1047576
      max_completion_tokens: 8192 # max: 32768
      temperature: 0.0
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0
      stop:
    cost_usd_mtok:
      input: 2.00
      output: 8.00
  gpt-4.1-nano:
    family: gpt-4.1
    engine: gpt-4.1-nano
    model_params:
      context_length: 8192 # max: 1047576
      max_completion_tokens: 8192 # max: 32768
      temperature: 0.0
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0
      stop:
    cost_usd_mtok:
      input: 0.10
      output: 0.40
  gpt-4.1-mini:
    family: gpt-4.1
    engine: gpt-4.1-mini
    model_params:
      context_length: 8192 # max: 1047576
      max_completion_tokens: 8192 # max: 32768
      temperature: 0.0
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0
      stop:
    cost_usd_mtok:
      input: 0.40
      output: 1.60
  chatgpt-4o-latest:
    family: gpt-4o
    engine: chatgpt-4o-latest
    model_params:
      context_length: 8192 # max: 128k
      max_completion_tokens: 8192 # max: 16384
      temperature: 0.0
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0
      stop:
    cost_usd_mtok:
      input: 5.00
      output: 15.00
  gpt-4o:
    family: gpt-4o
    engine: gpt-4o
    model_params:
      context_length: 8192 # max: 128k
      max_completion_tokens: 8192 # max: 16384
      temperature: 0.0
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0
      stop:
    cost_usd_mtok:
      input: 2.50
      output: 10.00
  gpt-4o-mini:
    family: gpt-4o
    engine: gpt-4o-mini
    model_params:
      context_length: 8192 # max: 128k
      max_completion_tokens: 8192 # max: 16384
      temperature: 0.0
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0
      stop:
    cost_usd_mtok:
      input: 0.15
      output: 0.60
  gpt-4:
    family: gpt-4
    engine: gpt-4
    model_params:
      context_length: 8192
      max_completion_tokens: 8192
      temperature: 0.0
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0
      stop:
    cost_usd_mtok:
      input: 30.00
      output: 60.00
  gpt-4-turbo:
    family: gpt-4
    engine: gpt-4-turbo
    model_params:
      context_length: 8192 # max: 128k
      max_completion_tokens: 4096
      temperature: 0.0
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0
      stop:
    cost_usd_mtok:
      input: 10.00
      output: 30.00
  gpt-3.5-turbo:
    family: gpt-3.5
    engine: gpt-3.5-turbo
    model_params:
      context_length: 8192 # max: 16385
      max_completion_tokens: 4096
      temperature: 0.0
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0
      stop:
    cost_usd_mtok:
      input: 0.50
      output: 1.50

deepseek:
  deepseek-v3:
    family: deepseek
    engine: deepseek-chat
    model_params:
      context_length: 8192 # max: 64k
      max_completion_tokens: 4096
      temperature: 0.0
      top_p: 1.0
      stop:
    cost_usd_mtok:
      input: 0.035 # discount price (orig. $0.07 USD)
      output: 0.550 # discount price (orig. $1.10 USD) 
  deepseek-r1:
    family: deepseek
    engine: deepseek-reasoner
    model_params:
      context_length: 8192 # max: 64k
      max_completion_tokens: 4096
      temperature: 0.0
      top_p: 1.0
      stop:
    cost_usd_mtok:
      input: 0.035 # discount price (orig. $0.14 USD)
      output: 0.550 # discount price (orig. $2.19 USD)

anthropic:
  claude-3.7-sonnet:
    family: claude
    engine: claude-3-7-sonnet-20250219
    model_params:
      context_length: 8192 # max: 200k
      max_completion_tokens: 8192 # max: 64k
      temperature: 0.0
      top_p: 1.0
      stop:
    cost_usd_mtok:
      input: 3.00
      output: 15.00
  claude-3.5-sonnet:
    family: claude
    engine: claude-3-5-sonnet-20241022
    model_params:
      context_length: 8192 # max: 200k
      max_completion_tokens: 8192
      temperature: 0.0
      top_p: 1.0
      stop:
    cost_usd_mtok:
      input: 3.00
      output: 15.00
  claude-3.5-haiku:
    family: claude
    engine: claude-3-5-haiku-20241022
    model_params:
      context_length: 8192 # max: 200k
      max_completion_tokens: 8192
      temperature: 0.0
      top_p: 1.0
      stop:
    cost_usd_mtok:
      input: 0.80
      output: 4.00
  claude-3-haiku:
    family: claude
    engine: claude-3-haiku-20240307
    model_params:
      context_length: 8192 # max: 200k
      max_completion_tokens: 4096
      temperature: 0.0
      top_p: 1.0
      stop:
    cost_usd_mtok:
      input: 0.25
      output: 1.25
  claude-3-opus:
    family: claude
    engine: claude-3-opus-20240229
    model_params:
      context_length: 8192 # max: 200k
      max_completion_tokens: 4096
      temperature: 0.0
      top_p: 1.0
      stop:
    cost_usd_mtok:
      input: 15.00
      output: 75.00

# The total context window is shared between input and output tokens.
# Max new tokens generated is limited to (context window - input tokens).
huggingface:
  gpt2:
    family: gpt2
    engine: openai-community/gpt2
    model_params:
      context_length: 1024
      max_new_tokens: 512
      temperature: 0.0
      top_p: 1.0
      do_sample: false
      stop:
    model_config:
      dtype: float32
      device_map: null
      ngpu: 1
  llama2-7b:
    family: llama-2
    engine: meta-llama/Llama-2-7b-chat-hf
    model_params:
      context_length: 4096
      max_new_tokens: 2048
      temperature: 0.0
      top_p: 1.0
      do_sample: false
      stop:
    model_config:
      dtype: float16
      device_map: null
      ngpu: 1
  llama2-13b:
    family: llama-2
    engine: meta-llama/Llama-2-13b-chat-hf
    model_params:
      context_length: 4096
      max_new_tokens: 2048
      temperature: 0.0
      top_p: 1.0
      do_sample: false
      stop:
    model_config:
      dtype: float16
      device_map: null
      ngpu: 2
    cost_usd_mtok:
      input: 0.52 # (when hosted on Azure)
      output: 0.67 # (when hosted on Azure)
  llama2-70b:
    family: llama-2
    engine: meta-llama/Llama-2-70b-chat-hf
    model_params:
      context_length: 4096
      max_new_tokens: 2048
      temperature: 0.0
      top_p: 1.0
      do_sample: false
      stop:
    model_config:
      dtype: float16
      device_map: null
      ngpu: 4
    cost_usd_mtok:
      input: 1.54 # (when hosted on Azure)
      output: 1.77 # (when hosted on Azure)
  llama3.1-405b:
    family: llama-3.1
    engine: meta-llama/Llama-3.1-405B-Instruct
    model_params:
      context_length: 8192 # max: 128k
      max_new_tokens: 2048
      temperature: 0.0
      top_p: 1.0
      do_sample: false
      stop:
    model_config:
      dtype: float16
      device_map: null
    cost_usd_mtok:
      input: 5.33 # (when hosted on Azure)
      output: 16.00 # (when hosted on Azure)
  llama3.1-70b:
    family: llama-3.1
    engine: meta-llama/Llama-3.1-70B-Instruct
    model_params:
      context_length: 8192 # max: 128k
      max_new_tokens: 2048
      temperature: 0.0
      top_p: 1.0
      do_sample: false
      stop:
    model_config:
      dtype: float16
      device_map: null
      npgu: 4
    cost_usd_mtok:
      input: 2.68 # (when hosted on Azure)
      output: 3.54 # (when hosted on Azure)
  llama3.1-8b:
    family: llama-3.1
    engine: meta-llama/Llama-3.1-8B-Instruct
    model_params:
      context_length: 8192
      max_new_tokens: 4096
      temperature: 0.0
      top_p: 1.0
      do_sample: false
      stop:
    model_config:
      dtype: float16
      device_map: null
      ngpu: 1
    cost_usd_mtok:
      input: 0.30 # (when hosted on Azure)
      output: 0.61 # (when hosted on Azure)
  codellama-7b:
    family: codellama
    engine: codellama/CodeLlama-7b-Instruct-hf
    model_params:
      context_length: 16384
      max_new_tokens: 2000
      temperature: 0.0
      top_p: 1.0
      stop:
    model_config:
      dtype: float16
      device_map: null
      ngpu: 1
  codellama-13b:
    family: codellama
    engine: codellama/CodeLlama-13b-Instruct-hf
    model_params:
      context_length: 16384
      max_new_tokens: 2000
      temperature: 0.0
      top_p: 1.0
      stop: "\n"
    model_config:
      dtype: float16
      device_map: null
      ngpu: 2
  codellama-34b:
    family: codellama
    engine: codellama/CodeLlama-34b-Instruct-hf
    model_params:
      context_length: 16384
      max_new_tokens: 2000
      temperature: 0.0
      top_p: 1.0
      stop: "\n"
    model_config:
      dtype: float16
      device_map: null
      ngpu: 4
  codellama-70b:
    family: codellama
    engine: codellama/CodeLlama-70b-Instruct-hf
    model_params:
      context_length: 16384
      max_new_tokens: 2000
      temperature: 0.0
      top_p: 1.0
      stop: "\n"
    model_config:
      dtype: float16
      device_map: null
      ngpu: 4